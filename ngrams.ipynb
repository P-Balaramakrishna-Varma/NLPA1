{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts = {}\n",
    "tokens = ['He', 'skipped', 'off', 'the', 'gunrest', 'and', 'looked', 'gravely', 'at', 'his', 'watcher', 'gathering', 'about', 'his', 'legs', 'the', 'loose', 'folds', 'of', 'his', 'gown']\n",
    "ngram_size = 4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_from_tokens_sen(tokens, ngram_size, Counts):\n",
    "    assert(ngram_size == Counts[\"NgramSize\"])\n",
    "    assert(type(ngram_size) == int and ngram_size > 0)\n",
    "    ngram = [\"w\" for i in range(ngram_size)]\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(ngram_size - 1):\n",
    "            ngram[j] = ngram[j + 1]\n",
    "        ngram[ngram_size - 1] = tokens[i]\n",
    "        \n",
    "        history = tuple((ngram[i] for i in range(ngram_size - 1)))\n",
    "        word = ngram[ngram_size - 1]\n",
    "\n",
    "        if history in Counts.keys():\n",
    "            if word in Counts[history].keys():\n",
    "                Counts[history][word] += 1\n",
    "            else:\n",
    "                Counts[history][word] = 1\n",
    "        else:\n",
    "            Counts[history] = {}\n",
    "            Counts[history][word] = 1\n",
    "\n",
    "\n",
    "def unigram_from_tokens_sen(tokens, Counts):\n",
    "    assert(Counts[\"NgramSize\"] == 1)\n",
    "    for token in tokens:\n",
    "        if token in Counts.keys():\n",
    "            Counts[token] += 1\n",
    "        else:\n",
    "            Counts[token] = 1\n",
    "\n",
    "\n",
    "def sum_values(Counts):\n",
    "    SumVal = {}\n",
    "    SumVal[\"NgramSize\"] == Counts[\"NgramSize\"]\n",
    "    if(SumVal[\"NgramSize\"] == 1):\n",
    "        SumVal[\"SUM\"] = sum(Counts.values())\n",
    "    else:\n",
    "        for history in Counts.keys():\n",
    "            SumVal[history] = sum(Counts[history].values())\n",
    "    return SumVal\n",
    "\n",
    "\n",
    "# extract from bigram\n",
    "def unigram_keser_nay_data(Counts):\n",
    "    assert(Counts[\"NgramSize\"] == 2)\n",
    "    keser_nay_unigram = {}\n",
    "    total_unique_bigrams = 0\n",
    "    for history in Counts.keys():\n",
    "        total_unique_bigrams += len(Counts[history].keys())\n",
    "    keser_nay_unigram[\"total_bigrams\"] = total_unique_bigrams\n",
    "    for history in Counts.keys():\n",
    "        for word in Counts[history].keys():\n",
    "            if word in keser_nay_unigram.keys():\n",
    "                keser_nay_unigram[word] += 1\n",
    "            else:\n",
    "                keser_nay_unigram[word] = 1\n",
    "    return keser_nay_unigram\n",
    "    \n",
    "                \n",
    "def conditional_prob(history, word, Counts, SumCounts):\n",
    "    assert(len(history) + 1 == Counts[\"NgramSize\"])\n",
    "    assert(Counts[\"NgramSize\"] == SumCounts[\"NgramSize\"])\n",
    "    if history in Counts.keys():\n",
    "        if word in Counts[history].keys():\n",
    "            return Counts[history][word] / SumCounts[history]\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def unigram_prob(word, Counts, SumCounts):\n",
    "    assert(Counts[\"NgramSize\"] == 1)\n",
    "    assert(SumCounts[\"NgramSize\"] == 1)\n",
    "    if word in Counts.keys():\n",
    "        return Counts[word] / SumCounts[\"SUM\"]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_from_tokens_sen(tokens, ngram_size, Counts)\n",
    "print(Counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def witten_bell_conditional(history, word, Counts_all, Sums_all, N):\n",
    "    assert(type(N) == int and N > 0)\n",
    "    assert(Counts_all[N][\"NgramSize\"] == N)\n",
    "    assert(Sums_all[N][\"NgramSize\"] == N)\n",
    "    assert(len(history) + 1 == N)\n",
    "    \n",
    "    # Base case\n",
    "    if N == 1:\n",
    "        return unigram_prob(word, Counts_all[N], Sums_all[N])\n",
    "    else:\n",
    "        if history in Counts_all[N].keys():\n",
    "            novel_history_words = len(Counts_all[N][history].keys())  #time compleixty O(1)\n",
    "            accourences_history = Sums_all[N][history].values()\n",
    "            prob_word_novel = novel_history_words / (accourences_history + novel_history_words)\n",
    "\n",
    "            if word in Counts_all[N][history].keys():\n",
    "                prob_cur = (1 - prob_word_novel) * Counts_all[N][history][word] / Sums_all[N][history]\n",
    "            else:\n",
    "                prob_cur = 0\n",
    "                \n",
    "            prob_recur = prob_word_novel * witten_bell_conditional(history[1:], word, Counts_all, Sums_all, N - 1)\n",
    "            return prob_cur + prob_recur\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keser_ney(history, word, Counts_all, Sums_all, kenser_uni ,N, d):\n",
    "    assert(d >= 0 and d <= 1)\n",
    "    assert(type(N) == int and N > 0)\n",
    "    assert(Counts_all[N][\"NgramSize\"] == N)\n",
    "    assert(Sums_all[N][\"NgramSize\"] == N)\n",
    "    assert(len(history) + 1 == N)\n",
    "    \n",
    "\n",
    "    # Base case\n",
    "    if N == 1:\n",
    "        if word in kenser_uni.keys():\n",
    "            return kenser_uni[word] / kenser_uni[\"total_bigrams\"]\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if history in Counts_all[N].keys():\n",
    "            novel_history_words = len(Counts_all[N][history].keys())  #time compleixty O(1)\n",
    "            occourences_history = Sums_all[N][history].values()\n",
    "            rec_weight = d * (novel_history_words / occourences_history)\n",
    "            \n",
    "            if word in Counts_all[N][history].keys():\n",
    "                cur_prob = max(0, Counts_all[N][history][word] - d) / occourences_history\n",
    "            else:\n",
    "                cur_prob = 0\n",
    "\n",
    "            recur_prob = keser_ney(history[1:], word, Counts_all, Sums_all, kenser_uni,N - 1, d)\n",
    "            return rec_weight * recur_prob + cur_prob\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likehood_of_sen_tokens(tokens, ngram_size, Counts_all, Sums_all, keser_uni, d, method):\n",
    "    assert(len(tokens) > 0)\n",
    "    likelyhood = 1\n",
    "    ngram = [\"w\" for i in range(ngram_size)]\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(ngram_size - 1):\n",
    "            ngram[j] = ngram[j + 1]\n",
    "        ngram[ngram_size - 1] = tokens[i]\n",
    "        \n",
    "        history = tuple((ngram[i] for i in range(ngram_size - 1)))\n",
    "        word = ngram[ngram_size - 1]\n",
    "\n",
    "        if method == \"witten_bell\":\n",
    "            likelyhood *= witten_bell_conditional(history, word, Counts_all, Sums_all, ngram_size)\n",
    "        elif method == \"keser_ney\":\n",
    "            likelyhood *= keser_ney(history, word, Counts_all, Sums_all, keser_uni, ngram_size, d)\n",
    "        else:\n",
    "            assert(False)\n",
    "    return likelyhood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81a2345993b7577bc27cad467612a9e6924e1c7dda3cbe531a1b9023471939ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
